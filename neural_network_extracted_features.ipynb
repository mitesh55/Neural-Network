{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FubE9djxXFtw"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "3atzZYs8Xyqk",
        "outputId": "6ae575b2-5e2a-477d-d042-828884b39313"
      },
      "source": [
        "data = pd.read_csv(r'/forestfires.csv')\r\n",
        "print(data.shape)\r\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(517, 31)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  month  day  FFMC   DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0   mar  fri  86.2  26.2  ...         0         0         0          small\n",
              "1   oct  tue  90.6  35.4  ...         0         1         0          small\n",
              "2   oct  sat  90.6  43.7  ...         0         1         0          small\n",
              "3   mar  fri  91.7  33.3  ...         0         0         0          small\n",
              "4   mar  sun  89.3  51.3  ...         0         0         0          small\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8RcPV5DYLcF",
        "outputId": "118bc994-1819-4344-fb26-aa37d6534a5a"
      },
      "source": [
        "# retreiving dummy variable columns for better analysis of data :\r\n",
        "original_data = data.iloc[:,0:11]\r\n",
        "# print(original_data.shape)     # (517, 11)\r\n",
        "original_data.head()\r\n",
        "original_data[\"size_category\"] = data[\"size_category\"]\r\n",
        "print(original_data.shape)       # (517, 12)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(517, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NmJdNa0YM6S"
      },
      "source": [
        "# Remove out liers in FFMC :\r\n",
        "original_data[\"FFMC\"] = original_data[\"FFMC\"].loc[original_data[\"FFMC\"]>80]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49suGehpYkaF"
      },
      "source": [
        "# Remove outliers from data base on  distibution :\r\n",
        "# original_data[\"ISI\"] = original_data[original_data.ISI<40]\r\n",
        "original_data[\"rain\"] = original_data[\"rain\"].loc[original_data.rain<2.5]\r\n",
        "original_data[\"area\"] = original_data[\"area\"].loc[original_data.area<400]\r\n",
        "# original_data.tail()\r\n",
        "original_data[\"ISI\"] = original_data[\"ISI\"].loc[original_data.ISI < 40]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkrwv8pAZACT"
      },
      "source": [
        "original_data = original_data.dropna(axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDXzTZP_ZEDF",
        "outputId": "f303dcb5-54bb-430a-b42a-c656bc31e07b"
      },
      "source": [
        "dummy_data = pd.get_dummies(original_data)\r\n",
        "print(dummy_data.shape)        # (501, 29)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(501, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdwyr5RKZOfC"
      },
      "source": [
        "# Feature Selection Method : Tree Based feature selection \r\n",
        "from sklearn.tree import DecisionTreeRegressor\r\n",
        "model = DecisionTreeRegressor()\r\n",
        "y = dummy_data[\"area\"]\r\n",
        "x = dummy_data.drop([\"area\"], axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY8OPpweZUK9",
        "outputId": "790460dc-6c99-4b41-ced7-ce2607d7db9c"
      },
      "source": [
        "model.fit(x,y)\r\n",
        "model.feature_importances_"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.36415337e-01, 6.48217798e-02, 5.88019035e-02, 7.75395023e-02,\n",
              "       1.87243142e-01, 4.17524529e-02, 1.44885072e-01, 8.87543356e-06,\n",
              "       0.00000000e+00, 6.50463057e-07, 5.73735952e-05, 6.89822494e-08,\n",
              "       0.00000000e+00, 1.22055797e-06, 8.34567857e-07, 8.15600998e-06,\n",
              "       0.00000000e+00, 6.27220125e-04, 8.40380829e-04, 7.09226762e-05,\n",
              "       2.55710048e-04, 3.19284746e-03, 3.04840037e-05, 7.69503689e-04,\n",
              "       1.35667157e-02, 1.65576068e-05, 2.69093289e-01, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCNvxnNrZXUN",
        "outputId": "0fc593d9-d21b-4729-cdda-08810f34117f"
      },
      "source": [
        "import numpy as np\r\n",
        "# to get columns index which has high impact to predict area :\r\n",
        "l = model.feature_importances_>0.01\r\n",
        "print(\"Index of columns which has high impact :\", np.where(l==True))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of columns which has high impact : (array([ 0,  1,  2,  3,  4,  5,  6, 24, 26]),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPIzemyEZnih"
      },
      "source": [
        "# Here, we can observe that individually month_august , month_september , month_july has high impact but in case of combining whole feature together month_april has high impact on area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZjb15pAZpfe",
        "outputId": "21503404-d39d-4372-c249-95e71f678c11"
      },
      "source": [
        "final_x = dummy_data.iloc[:,[0,  1,  2,  3,  4,  5,  6, 24, 26]]\r\n",
        "final_x.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(501, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76cq6xudZ7L-"
      },
      "source": [
        "import keras\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "# Standardization\r\n",
        "a = StandardScaler()\r\n",
        "a.fit(final_x)\r\n",
        "x_standardized = a.transform(final_x)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_fP47KyaJUR"
      },
      "source": [
        "# Importing the necessary packages\r\n",
        "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout\r\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\r\n",
        "from keras.optimizers import Adam, Adadelta"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJiH-yHSaRhc",
        "outputId": "7e8a23c0-cf28-4a1b-dadc-64eae0768d69"
      },
      "source": [
        "# create base model :\r\n",
        "kfold = KFold(n_splits=10)\r\n",
        "def create_model():\r\n",
        "  m = Sequential()\r\n",
        "  m.add(Dense(16, input_dim=9, kernel_initializer='normal', activation='relu'))\r\n",
        "  m.add(Dense(12, kernel_initializer='normal', activation='relu'))\r\n",
        "  m.add(Dense(8, kernel_initializer='normal', activation='relu'))\r\n",
        "  m.add(Dense(1, kernel_initializer='normal'))\r\n",
        "  adam = Adam(lr=0.01)\r\n",
        "  m.compile(loss='mean_squared_error', optimizer=adam)\r\n",
        "  return m\r\n",
        "model = create_model()\r\n",
        "history_1 = model.fit(np.array(x_standardized), np.array(y), epochs=100)\r\n",
        "print(\"********************************done***********************************\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 2s 2ms/step - loss: 856.5717\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 928.4283\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 862.9008\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 573.7295\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 672.2999\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 558.8751\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 718.7888\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 553.5658\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 474.2340\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 929.5611\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 791.0137\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 920.8695\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 559.2055\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 618.1688\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 545.5262\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 433.1335\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 842.0406\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 784.9051\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 572.9463\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 844.0302\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 796.2387\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 752.0417\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 887.6816\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1071.4333\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 914.6022\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 534.2221\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 574.5137\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 772.6059\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1181.6230\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 581.4108\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 971.3444\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 728.4822\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 899.0207\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 823.8114\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 766.2372\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 677.9437\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 707.7476\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 835.4713\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 694.6008\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 443.6057\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 605.1934\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 626.9043\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 645.5058\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 753.0436\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1068.4708\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 586.8772\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 603.1929\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 826.1485\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 568.5772\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 786.9841\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 839.2174\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 728.9135\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 757.1685\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 558.1545\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 798.2092\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 649.7327\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 573.9465\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 604.4201\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 717.4785\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 612.1260\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 596.6695\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 740.4278\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 642.9578\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 516.2504\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 592.8454\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 650.2199\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 763.0541\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 861.5359\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 679.4218\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 979.8102\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 601.1522\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 720.0378\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 591.0730\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 669.2082\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 728.5377\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 841.8961\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 525.3366\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 710.9368\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 510.7696\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 854.2828\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 624.5635\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 649.3913\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 528.4945\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 519.0904\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 526.2956\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 601.2942\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 488.1275\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 764.3653\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 435.6513\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 428.4729\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 667.9831\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 433.8106\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 526.2036\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 405.7198\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 544.4604\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 475.7151\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 365.2556\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 389.0041\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 423.6777\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 413.6187\n",
            "********************************done***********************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kMWqMENcK0c",
        "outputId": "b7410140-b064-4df5-c341-cab888c64460"
      },
      "source": [
        "history_1.history.keys()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_P5qO4KcQoE"
      },
      "source": [
        "# prediction for base model :\r\n",
        "y_pred = model.predict(x_standardized)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY618tTpck4q",
        "outputId": "d763febf-596b-4f9f-a4bd-47193c6dcea9"
      },
      "source": [
        "from sklearn.metrics import r2_score\r\n",
        "print(r2_score(y_pred, y))       # 41.45 % "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.4144714404448768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ZJ0FHAcJc2Nr",
        "outputId": "b791713a-e612-4420-81d4-210478dbd3f7"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.scatter(y_pred, y)\r\n",
        "plt.xlabel(\"predicted value\")\r\n",
        "plt.ylabel(\"actual value\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'actual value')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb9UlEQVR4nO3df5TcdX3v8ecr6wKrUBdMzE2WYFIa44VyTHChKF4LqATotYkca+Haiq1tPBV6QL05Ta7eI957LemJP6pt5QjKAQsXQjWGVKgREaHkGHQhISFAJECALIGkYIArq4bN+/7x/c5kspnZ/e7ufOfX9/U4Z87OfOb7/c57vmd23vP9/FREYGZmBjCl2QGYmVnrcFIwM7MyJwUzMytzUjAzszInBTMzK3tNswOYjKlTp8bs2bObHYaZWVu57777/iMiplV7rq2TwuzZsxkYGGh2GGZmbUXSk7Wec/WRmZmVOSmYmVmZk4KZmZU5KZiZWZmTgpmZlbV17yMzs6JZs3GQleu28czeIWb29rB04TwWL+ir2/GdFMzM2sSajYMsX72FoX3DAAzuHWL56i0AdUsMrj4yM2sTK9dtKyeEkqF9w6xct61ur+GkYGbWJp7ZOzSu8olwUjAzaxMze3vGVT4RTgpmZm1i6cJ59HR3HVTW093F0oXz6vYabmg2M2sTpcZk9z4yMzMgSQz1TAIjufrIzMzKnBTMzKzMScHMzMqcFMzMrMxJwczMypwUzMyszEnBzMzKnBTMzKzMScHMzMqcFMzMrMxJwczMypwUzMysLLekIGmWpDslPSRpq6RL0/LLJQ1K2pTezqvYZ7mk7ZK2SVqYV2xmZlZdnrOkvgp8KiLul3QUcJ+k29PnvhwRX6jcWNIJwAXAicBM4IeS3hwRB689Z2ZmucntSiEidkXE/en9l4GHgdHme10E3BQRv46IJ4DtwKl5xWdmZodqSJuCpNnAAuDetOgSSZslXSPp6LSsD3i6YredVEkikpZIGpA0sGfPnhyjNjMrntyTgqQjge8Al0XES8CVwPHAfGAX8MXxHC8iroqI/ojonzZtWt3jNTMrslyTgqRukoRwQ0SsBoiI5yJiOCL2A1dzoIpoEJhVsfuxaZmZmTVInr2PBHwTeDgivlRRPqNis/cDD6b31wIXSDpc0hxgLvDTvOIzM7ND5dn76HTgT4EtkjalZf8DuFDSfCCAHcDHACJiq6SbgYdIei5d7J5HZmaNlVtSiIh7AFV56rZR9vk88Pm8YjIzs9F5RLOZmZU5KZiZWZmTgpmZlTkpmJlZmZOCmZmVOSmYmVmZk4KZmZU5KZiZWZmTgpmZlTkpmJlZmZOCmZmVOSmYmVmZk4KZmZU5KZiZWZmTgpmZlTkpmJlZmZOCmZmVOSmYmVlZnms0W0Gs2TjIynXbeGbvEDN7e1i6cB6LF/Q1OywzmwAnBZuUNRsHWb56C0P7hgEY3DvE8tVbAJwYzNqQq49sUlau21ZOCCVD+4ZZuW5bkyIys8lwUrBJeWbv0LjKzay1OSnYpMzs7RlXuZm1NicFm5SlC+fR0911UFlPdxdLF85rUkRmNhluaLZJKTUmu/eRWWdwUrBJW7ygz0nArEM4KVjb8zgJs/rJrU1B0ixJd0p6SNJWSZem5cdIul3So+nfo9NySfqqpO2SNks6Oa/YrHOUxkkM7h0iODBOYs3GwWaHZtaW8mxofhX4VEScAJwGXCzpBGAZcEdEzAXuSB8DnAvMTW9LgCtzjM06hMdJmNVXbtVHEbEL2JXef1nSw0AfsAg4I93sOuDHwN+k5d+KiAA2SOqVNCM9TkO5OqJ9eJyEWX01pEuqpNnAAuBeYHrFF/2zwPT0fh/wdMVuO9OykcdaImlA0sCePXvqHqurI9qLx0mY1VfuSUHSkcB3gMsi4qXK59KrghjP8SLiqojoj4j+adOm1THShKsj2ovHSZjVV669jyR1kySEGyJidVr8XKlaSNIMYHdaPgjMqtj92LSsoVwd0V48TsKsvnJLCpIEfBN4OCK+VPHUWuAiYEX695aK8ksk3QT8HvBiM9oTZvb2MFglAbg6onV5nIRZ/eRZfXQ68KfAWZI2pbfzSJLBeyU9CrwnfQxwG/A4sB24Gvh4jrHV5OoIMyuyPHsf3QOoxtPvrrJ9ABfnFU9Wro4wsyLziOYqXB1hZkXlpGBmheExSGNzUjCzQvDSsdl4PQUzKwSPQcrGScHMCsFjkLJxUjCzQvCUKNk4KZhZIXgMUjZuaDazQvAYpGycFMysMDwGaWxjJgVJ04G/BWZGxLnpQjlvj4hv5h5dm3JfaDNrV1naFK4F1gEz08c/By7LK6B25/UYzKydZUkKUyPiZmA/QES8CgyPvktxuS+0mbWzLEnhl5LeQLoYjqTTgBdzjaqNuS+0mbWzLA3NnyRZ6+B4SeuBacAHco2qjXk9BjNrZ2NeKUTE/cDvA+8APgacGBGb8w6sXbkvtJm1syy9jz48ouhkSUTEt3KKqa25L7SZtbMs1UenVNw/gmSBnPsBJ4Ua3BfazNrVmEkhIv668rGkXuCm3CIyM7OmmcjcR78E5tQ7EDMza74sbQr/StodlSSJnADcnGdQZmbWHFnaFL5Qcf9V4MmI2JlTPGZm1kRZ2hTuakQgZmbWfDWTgqSXOVBtdNBTQETEb+UWlZmZNUXNpBARRzUyELNO4VlyrZ1lXk9B0htJxikAEBFP5RKRWRsrzZJbmhSxNEsu4MRgbWHMLqmS/lDSo8ATwF3ADuDfco7LrC15llxrd1nGKfxv4DTg5xExh2RE84axdpJ0jaTdkh6sKLtc0qCkTentvIrnlkvaLmmbpIUTeC9mTedZcq3dZUkK+yLieWCKpCkRcSfQn2G/a4FzqpR/OSLmp7fbANLV3C4ATkz3+Zqkrir7mrW0WrPhepZcaxdZksJeSUcCdwM3SPoKyajmUUXE3cALGeNYBNwUEb+OiCeA7cCpGfc1axmeJdfaXZaksAh4BfgE8H3gMeB9k3jNSyRtTquXjk7L+oCnK7bZmZYdQtISSQOSBvbs2TOJMMzqb/GCPq44/yT6ensQ0NfbwxXnn+RGZmsbWXoffQxYFRGDwHWTfL0rSdooIv37ReDPx3OAiLgKuAqgv7+/2jgKs6byLLnWzrJcKRwF/EDSv0u6RNL0ib5YRDwXEcMRsR+4mgNVRIPArIpNj03LzMysgbKsvPa5iDgRuBiYAdwl6YcTeTFJMyoevh8o9UxaC1wg6XBJc4C5wE8n8hpmZjZxmQevAbuBZ4HngTeOtbGkG4EzgKmSdgKfBc6QNJ+k+mgHSdUUEbFV0s3AQyST7l0cEcPVjmtmZvlRxOjV8pI+DnwQmAb8C3BzRDzUgNjG1N/fHwMDA80Ow8ysrUi6LyKqDi3IcqUwC7gsIjbVNywzM2s1WabOXt6IQMzMrPkmshynmZl1KCcFMzMrc1IwM7Myr7xmZmZlXnnNzMzKvPKamZmVeeU1MzMry23lNTMzaz95rrxmZmZtJkubwsiV13aTYeU1MzNrP1lXXhuifiuvmZlZi8oy91HlVcFkV14zM7MWNmZSGDGI7TCgG/ilB6+ZmXWeLFcK5UFskkRSnXRankGZmVlzjGvuo0isARbmFI+ZmTVRluqj8yseTiHpjvqr3CIyM7OmydIltbKn0askI5oX5RKNmZk1VZak8I2IWF9ZIOl0YHc+IZmZWbNkaVP4h4xlZmbW5kZbT+HtwDuAaZI+WfHUbwFdeQdmZmaNN1r10WHAkek2lWsrvAR8IM+gzMysOUZbZOcu4C5J10bEkw2MqeWs2TjIynXbeGbvEDN7e1i6cB6LF/Q1Oywzs7rL0qbwDUm9pQeSjpa0LseYWsqajYMsX72Fwb1DBDC4d4jlq7ewZuNgs0MzM6u7LL2PpkbE3tKDiPhFugpbIaxct42hfcMHlQ3tG2blum1td7XgKx4zG0uWpLBf0nGl5TclvYkDcyF1vGf2Do2rvFWVrnhKCa50xQM4MZhZWZbqo08D90j6Z0nXk6yrsHysnSRdI2m3pAcryo6RdLukR9O/R6flkvRVSdslbZZ08kTfUL3N7O0ZV3mrGu2Kx8ysZMykEBHfB04GVgE3AW+LiCxtCtcC54woWwbcERFzgTvSxwDnAnPT2xLgyizBN8LShfPo6T64B25PdxdLF85rUkQT0ylXPGaWr6wT4g2TjGB+CThB0rvG2iEi7gZeGFG8iANrMlwHLK4o/1Y64d4GoFfSjIyx5Wrxgj6uOP8k+np7ENDX28MV55/UdlUunXLFY2b5GjMpSPoLkiqjdcDn0r+XT/D1pkfErvT+s8D09H4f8HTFdjvTsmrxLJE0IGlgz549Ewwju05pnO2UKx4zy1eWK4VLgVOAJyPiTGABsHf0XcYWEcEEGqwj4qqI6I+I/mnTpk02jFF1UnfUTrniMbN8Zel99KuI+JUkJB0eEY9ImujPy+ckzYiIXWn1UGlSvUFgVsV2x6ZlTdVJ3VEhSQztGLeZNU6WK4Wd6eC1NcDtkm4BJjrCeS1wUXr/IuCWivIPp72QTgNerKhmaho3zppZ0WRZjvP96d3LJd0JvB74/lj7SboROAOYKmkn8FlgBXCzpI+SJJYPppvfBpwHbAdeAf5sfG8jHzN7exiskgDcOGtmnSpL9VFZOh9S1m0vrPHUu6tsG8DF44mlEZYunHfQgC+YeONspzRYm1lnG1dSKJrSl/Zkv8w9mtjM2oWTwhjq0TjbaQ3W1fhKyKwzOCk0QKc3WPtKyKxzZB3RbJPQ6aOJs86rtGbjIKev+BFzlt3K6St+1JbjPcw6nZNCA3T6aOIsV0KdNBDQrJM5KTRAp48mznIl5FlazdqD2xQapJNHE2fputvp7SpmncJXCjZpWa6EOr1dxaxT+ErB6mKsK6F6DgQ0s/w4KVhD1GsgoJnly0nBGqaT21XMOoWTQoF41LGZjcVJYZza9Yu1HUYdt+u5Nesk7n00Du08AKvVxwm087k16yROCuPQ6l+so2n1cQLtfG7NOomTwji0+hfraFp9nEA7n1uzTuKkkEFpIreo8XyrfLGOptXnX2r1pGVWFE4KY6is666mlb5YR9Pq8y+1etIyKwr3PhpDtbrukr426yHTyuMEPLjNrDU4KYxhtDrtZ/YOlRtC/eU1ea2ctMyKwtVHYxitTttdJ82s0zgpjKFaXfdIXmXMzDqFq49GURphO7RvmC6J4ajV/6j6KmOtPHrYzKwaJ4UaRn6xD0fQ093FEd1T+MUr+w7ZPusqY6Wk4CkdzKwVOSnUUOuL/fDXTKGnu2tSq4z5SsLMWlXh2hSy1vXX+mJ/cWjfpFcZ85QOZtaqmnKlIGkH8DIwDLwaEf2SjgFWAbOBHcAHI+IX9Xzd8fxCn9nbU3XA2szenkmvMuYpHcysVTXzSuHMiJgfEf3p42XAHRExF7gjfVxX4/mFPvsNh/7azzrCdqzRw57SwcxaVSu1KSwCzkjvXwf8GPiber5ArakqRpZ/Zs0W1j/2wiHbnXzc6zPX+Y92NeH1is2sVTUrKQTwA0kBfD0irgKmR8Su9PlngenVdpS0BFgCcNxxx43rRUfrVjpn2a3lXkA33vt01W02PF6f2ixP6WBmrapZSeGdETEo6Y3A7ZIeqXwyIiJNGIdIE8hVAP39/bUHDlQx2jiDytHJtbYbbf/x8pQOZtaKmtKmEBGD6d/dwHeBU4HnJM0ASP/urvfr9mWos681+R2A6hmMmVkLanhSkPQ6SUeV7gNnAw8Ca4GL0s0uAm6p92tnmbJiNFOmyNNVmFlHa8aVwnTgHkkPAD8Fbo2I7wMrgPdKehR4T/q4rkb2CupS7d/+1Z4Z3h8eS2BmHa3hbQoR8Tjw1irlzwPvzvv1K+vy12wc5LJVm6puV6v1oFYPJjOzTtBKXVIbpjTv0ES+4Ee7ujAza3eFSwojRzWPVz17IJmZtZrCzX002vKaWRz92u46RmNm1loKlxSyzi9Uq5LIFwpm1skKV31Ua6K7kWp99784dOhaCll4/QQzaweFu1KY7FiFiUxaV2rHGNw75HWdzaylFS4pVI5VGK+JTlrn9RPMrF0ULilAkhjWLztrXInhtd1TOKJ7Cp9YtemQxXnGWrjH6yeYWbsoXJtCpfF8Kb+ybz+v7NsPHKj+GXjyBW7dvOugNZurLdwz2oI9ZmatpJBXCiW9k+heOrRvmOs3PHVQQqh8rrJqqFo7htdPMLNWVOgrhTy7l1ZehXj9BDNrF4VOChPtXprFyKohr59gZu2g0NVHedXpu2rIzNpVoZPCZMcsVNPb080V55/kqwIza0uFrj4qfXF/YtWmmiOYx2vTZ8+u05HMzBqvsEmhcvrsKcre6Nw1RQzvr75xnpPleZoMM2uEQiaFkdNn1/iOr2p4f6AaSSSv3kwj4602FsLMrB4K2abwuX/dOqnps2t9+efVm8nTZJhZoxQuKXxmzZaqA87qIa/eTJ4mw8wapVDVR2s2DnL9hqdyOfYUyNwNdWT7wJlvmcadj+yp2V7gaTLMrFEKdaVw+dqtuR17PzDw5AtjbldtGu3rNzw16rTanibDzBqlUElhb44jmAFuuHfsq5Asy4GObC+onO5bQF9vj8dCmFkuClV9lLcIOH75bQxH0CVx4e/N4v8sPumgbbK2A4zcrp7TZLh7q5nVUqgrhcO6aq28XD/Dadek4Qiu3/AUH7r6Jwc9n7UdIK/2Aq8CZ2ajKVRS+M1wjtOi1rD+sRfGbB8YKc/2AndvNbPRuPqoAS5btYmV67YdVE0znt5H9dTs7q2uujJrbU4KDTK4d4il336AgSdfaFgCqKaZ3Vs9Mtus9bVcUpB0DvAVoAv4RkSsaHJIdbNvOA4aJ1FKFJev3cqLQ/uqJonx/LLOsu3ShfMO+mKGbNVVWY491jajVV05KZi1hpZKCpK6gH8C3gvsBH4maW1EPNTcyPKzbzjKXWVH/nIezy/rrNtOZBW4LMfOsk2zq67MbGyt1tB8KrA9Ih6PiN8ANwGLmhxTQ1U2+o6nUXg82y5e0Mf6ZWfxxIo/YP2ys8b8lZ7l2Fm2qVVF5ZHZZq2j1ZJCH/B0xeOdaVmZpCWSBiQN7Nmzp6HBNUrpl/N4flnn+Ss8y7GzbOOR2Watr9WSwpgi4qqI6I+I/mnTpjU7nFyUfjmP55d1nr/Csxw7yzYemW3W+lotKQwCsyoeH5uWdaTXHdZF95SDB9RV/nIezy/rPH+FZzl21tcfb9WVmTVWqyWFnwFzJc2RdBhwAbC2XgffseIP6nWomiq/4nt7uvmT046jL/213KXk2b7eHv7+j+ez9X+dw8o/emvNX87j+WWd56/wLMf2VYBZZ1DktVzYBEk6D/h7ki6p10TE52tt29/fHwMDAw2LzcysE0i6LyL6qz3XUl1SASLiNuC2ZsdhZlZErVZ9ZGZmTeSkYGZmZU4KZmZW5qRgZmZlLdf7aDwk7QGenMCuU4H/qHM47cjn4QCfi4TPQ6LTz8ObIqLq6N+2TgoTJWmgVnesIvF5OMDnIuHzkCjyeXD1kZmZlTkpmJlZWVGTwlXNDqBF+Dwc4HOR8HlIFPY8FLJNwczMqivqlYKZmVXhpGBmZmWFSwqSzpG0TdJ2ScuaHU8jSdohaYukTZIG0rJjJN0u6dH079HNjrPeJF0jabekByvKqr5vJb6afj42Szq5eZHXV43zcLmkwfQzsSmdpbj03PL0PGyTtLA5UdefpFmS7pT0kKStki5Nywv3maimUElBUhfwT8C5wAnAhZJOaG5UDXdmRMyv6IO9DLgjIuYCd6SPO821wDkjymq973OBueltCXBlg2JshGs59DwAfDn9TMxPZykm/b+4ADgx3edr6f9PJ3gV+FREnACcBlycvt8ifiYOUaikAJwKbI+IxyPiN8BNwKImx9Rsi4Dr0vvXAYubGEsuIuJu4IURxbXe9yLgW5HYAPRKmtGYSPNV4zzUsgi4KSJ+HRFPANtJ/n/aXkTsioj70/svAw+TrAVfuM9ENUVLCn3A0xWPd6ZlRRHADyTdJ2lJWjY9Inal958FpjcntIar9b6L+Bm5JK0Wuaai+rAQ50HSbGABcC/+TADFSwpF986IOJnkcvhiSe+qfDKS/smF66Nc1PeduhI4HpgP7AK+2NxwGkfSkcB3gMsi4qXK54r8mShaUhgEZlU8PjYtK4SIGEz/7ga+S1Id8FzpUjj9u7t5ETZUrfddqM9IRDwXEcMRsR+4mgNVRB19HiR1kySEGyJidVrszwTFSwo/A+ZKmiPpMJKGtLVNjqkhJL1O0lGl+8DZwIMk7/+idLOLgFuaE2HD1Xrfa4EPpz1OTgNerKhS6Dgj6sbfT/KZgOQ8XCDpcElzSBpZf9ro+PIgScA3gYcj4ksVT/kzARARhboB5wE/Bx4DPt3seBr4vn8beCC9bS29d+ANJD0tHgV+CBzT7FhzeO83klSN7COpD/5orfcNiKSH2mPAFqC/2fHnfB7+OX2fm0m+/GZUbP/p9DxsA85tdvx1PA/vJKka2gxsSm/nFfEzUe3maS7MzKysaNVHZmY2CicFMzMrc1IwM7MyJwUzMytzUjAzszInBbMKks6Q9L30/h+ONpOupF5JH5/Aa1wu6b9PJs56HseskpOCFcJEZviMiLURsWKUTXqBcScFs1bmpGBtTdJsSY9IukHSw5K+Lem16XM7JP2dpPuBP5J0tqSfSLpf0r+kc9+U1th4JN3u/Ipjf0TSP6b3p0v6rqQH0ts7gBXA8ek6BCvT7ZZK+lk6wdznKo71aUk/l3QPMK/K+3i9pCclTUkfv07S05K6Jf1leswHJH2n9P5G7P9jSf3p/amSdqT3uyStrIjpY/U589apnBSsE8wDvhYR/xl4iYN/vT8fySSAPwQ+A7wnfTwAfFLSESRz/rwPeBvwn2q8xleBuyLircDJJKPClwGPRbIOwVJJZ5NMB3EqyQRzb5P0LklvI5lSZT7JyNlTRh48Il4kGVn7+2nRfwXWRcQ+YHVEnJK+9sMkI5Gz+ijJtAynpK/7l+m0FWZVOSlYJ3g6Itan968nmcagZFX69zSShZXWS9pEMrfNm4C3AE9ExKORDO+/vsZrnEW6uEokE8i9WGWbs9PbRuD+9Nhzgf8CfDciXolkNs5a822tAv44vX9BRey/K+nfJW0BPkSy8E1WZ5PM27OJZHroN6QxmVX1mmYHYFYHI+dqqXz8y/SvgNsj4sLKDSXNr2McAq6IiK+PeI3LMu6/FvhbSceQXLX8KC2/FlgcEQ9I+ghwRpV9X+XAj7wjRsT01xGxLmMMVnC+UrBOcJykt6f3/xtwT5VtNgCnS/odKNfZvxl4BJgt6fh0uwur7AvJRGl/le7bJen1wMvAURXbrAP+vKKtok/SG4G7gcWSetKZat9X7QUi4v+RzOT7FeB7ETGcPnUUsCud7vlDNeLbQZJIAD4wIqa/SvdF0pvTWXLNqnJSsE6wjWTRoIeBo6myhm5E7AE+AtwoaTPwE+AtEfErknV3b00bmmutJ3EpcGZahXMfcEJEPE9SHfWgpJUR8QPg/wI/Sbf7NnBUJEs/riKZofbfSL74a1kF/AkHqo4A/idJ1c96kiRWzRdIvvw3AlMryr8BPATcL+lB4Ou4hsBG4VlSra0pWU7xexHxu00Oxawj+ErBzMzKfKVgZmZlvlIwM7MyJwUzMytzUjAzszInBTMzK3NSMDOzsv8PZOGs3E/uYvcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwBw4WQpc9DN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_standardized, y, test_size=0.25, random_state=7)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwpRwSo1dmon",
        "outputId": "aaf2ff2f-067a-41c2-8089-411cb3c454c2"
      },
      "source": [
        "# train data on base model :\r\n",
        "history_2 = model.fit(np.array(x_train), np.array(y_train), epochs=500)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 98.4749\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 103.2954\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 104.6913\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 102.9873\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 95.7735\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 97.7983\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 95.1973\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 101.3646\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 101.2751\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 107.1635\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 107.1559\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 98.0544\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 94.3732\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 102.1527\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 97.8942\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 100.0577\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 93.1700\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 155.4644\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 113.3655\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 114.8571\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 106.6221\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 108.1140\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 125.8011\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 101.4922\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 101.7086\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 100.8551\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 99.0938\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 101.7922\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 102.4056\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 107.3427\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 113.3590\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 228.6507\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 132.3421\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 143.2316\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 125.7219\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 119.6289\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 121.0671\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 105.0757\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 103.4167\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 104.1415\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 110.1260\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 106.3792\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 112.4454\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 121.0617\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 120.3125\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 120.4184\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 111.9628\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 108.1621\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 106.2098\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 103.1288\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 102.1929\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 103.4062\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 99.4596\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 101.3203\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 160.0895\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 132.0938\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 130.5290\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 132.9177\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 130.9063\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 127.7827\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 125.5037\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 130.1563\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 129.2961\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 128.5003\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.8389\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.7394\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6785\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.7407\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 127.8719\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.8545\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.7916\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.8285\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.7219\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 127.7113\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 127.7864\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.8840\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6071\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6634\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6058\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.5614\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6404\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.7583\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 127.5828\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6803\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.5496\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.5456\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.6616\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 127.9069\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 127.8904\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 128.5795\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 128.8961\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 129.6428\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 131.1331\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 133.3615\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 141.5482\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 144.7915\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 142.7660\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 146.0721\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 204.8434\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 279.3651\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 244.0278\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 248.2578\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 248.2953\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 253.7077\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 247.5554\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 243.5039\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 240.4379\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.5629\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.4507\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.5661\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.1243\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.3210\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.3880\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 237.4641\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 321.4858\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 261.7816\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 259.5054\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 245.3397\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 247.6098\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 282.1630\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 278.5868\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 299.7575\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 278.2320\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 294.4103\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 273.7258\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 328.2922\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 279.6600\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 422.8879\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 402.9153\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 359.3078\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 276.3034\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 271.1232\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 281.7401\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 281.3022\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 256.7398\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 248.7319\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 244.1333\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 241.4083\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 238.6508\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 237.3961\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 236.7520\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 236.5494\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.9222\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 235.5683\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.4307\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.8240\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.9038\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.4543\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.4578\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.4011\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.1593\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.4645\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.9084\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.8503\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.7384\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.7581\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.7194\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 237.5746\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.7794\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.3661\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.4023\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.3218\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.6358\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.0021\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.7891\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.0357\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.6522\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.7430\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.7834\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.3274\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.2520\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.6801\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.3447\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.6354\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.0055\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.3994\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.8053\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.6551\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.1649\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.7667\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.7259\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.3970\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.3646\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.4645\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.4320\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.6365\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.1239\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.4423\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.3647\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.0017\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.0801\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.5362\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.0955\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.7876\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.9919\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.5020\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.9529\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.2150\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 235.1722\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 235.5719\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 236.4515\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 248.7052\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 243.8573\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 263.3672\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 249.2618\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 257.5656\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 257.7573\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 254.2472\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 254.3974\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 249.1415\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 242.2216\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 240.1851\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 235.1442\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.7692\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.5595\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.8491\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.9215\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.7043\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.2993\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.6247\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.4884\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.4657\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.1843\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.8236\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.4642\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.9825\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.8162\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.9426\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.6147\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.2479\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.2873\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0750\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.0076\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9904\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9969\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.4063\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9938\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0547\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.1935\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.1960\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9423\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0312\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9986\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9442\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0065\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9496\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9620\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9613\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9960\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9787\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0107\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.0336\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.0098\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9861\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.9886\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.0757\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0595\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0786\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.0118\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.1372\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.1541\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.3138\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.1866\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.3168\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.1836\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.2845\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.4227\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.5105\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.3324\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.4935\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.6138\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.0195\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.9217\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.9317\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.1536\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.9771\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 237.0063\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 239.9424\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 243.2378\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 252.8178\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 261.3206\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 459.5681\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 385.4672\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 356.7591\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 392.9417\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 377.6542\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.3555\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 358.0746\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 293.2713\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 339.8770\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 571.0242\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 546.2580\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 475.4579\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 359.8318\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 287.0970\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 267.4928\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 275.7650\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 255.9459\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 257.6949\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 247.8172\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 252.0646\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 255.8860\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 298.7722\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 384.8158\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 322.4547\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 326.2318\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 281.6627\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 245.9998\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.9593\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 236.1516\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 236.7694\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 270.8085\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 326.3060\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 245.6400\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 316.0689\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 350.6183\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 275.7183\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 262.6476\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 243.8831\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.6891\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 237.0791\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.9354\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.4040\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.6300\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 233.0782\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.2243\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 233.0462\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.2278\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 236.4124\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.7079\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 235.0376\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.1994\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.7917\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 234.0316\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.0104\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.7946\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 232.1897\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.6042\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.6661\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.3279\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2483\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2376\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2060\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2368\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0933\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1219\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2268\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1317\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1847\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1057\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0996\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1173\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1083\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1958\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2635\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1102\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.1006\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0963\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0583\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0696\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0508\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1134\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0730\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1187\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0569\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0801\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0387\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1469\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2363\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0831\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0782\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1002\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1017\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0964\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1149\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.3667\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0610\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1476\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1424\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2373\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0634\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0931\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1487\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1071\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1570\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1691\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.4428\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2132\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0677\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1023\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.0909\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2888\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1037\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1044\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0644\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.0640\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1477\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0738\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.3063\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1190\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0789\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1049\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2184\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0570\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0805\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1582\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1359\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0835\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0721\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0538\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1385\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1432\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0808\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1937\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1079\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0723\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0516\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0494\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0894\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1223\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0790\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1351\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0881\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.0922\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2276\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0820\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1109\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2236\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1783\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0706\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.0703\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1639\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.2257\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2393\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.1495\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2855\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.3629\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.3652\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.6049\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.4642\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.3761\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.4759\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2696\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.2490\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.4917\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 231.8737\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 231.9918\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 232.7818\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 236.0789\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 236.7747\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.1287\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 236.7804\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 243.2554\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 284.6642\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 398.6592\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 446.7576\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 414.9518\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 392.7639\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 388.2637\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 385.0588\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 381.6969\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 376.0174\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 371.9344\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 372.2697\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 371.2548\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.8207\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.7838\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.7205\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.6126\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.5205\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.5096\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.5252\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.3811\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.4505\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.6307\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.7853\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.3888\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.4173\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.3938\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 370.4845\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.3812\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 370.0860\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 313.6445\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 328.9763\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 378.9327\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 302.1502\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 331.9217\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 319.1372\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 332.9135\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 300.6688\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 278.5214\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 275.6995\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 259.3145\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 243.5110\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 236.7464\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 235.5606\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 236.6677\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 238.1614\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 234.6815\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 239.8324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPKskhtgd5OX"
      },
      "source": [
        "# training accuracy of base model :\r\n",
        "y_train_pred = model.predict(x_train)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etlIStK5ec_W",
        "outputId": "4ef140cf-b3f4-4b03-c225-1b1e0b876d77"
      },
      "source": [
        "print(\"training accuracy :\", r2_score(y_train_pred, y_train))     # 67.34 % training accuracy "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy : 0.6733871227667514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htP2RUkhepfw"
      },
      "source": [
        "# testing accuracy :\r\n",
        "y_test_pred = model.predict(x_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ti84S1Ie7Zy",
        "outputId": "7eaceb7b-1d14-46cb-d541-edae118c306e"
      },
      "source": [
        "print(\"testing accuracy :\", r2_score(y_test_pred, y_test))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing accuracy : -3.522785673255787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRymoK46fH8x",
        "outputId": "504a44b7-0d13-442b-93e0-086251ae32e1"
      },
      "source": [
        "# create general model which is use to find better parameter :\r\n",
        "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\r\n",
        "    m = Sequential()\r\n",
        "    m.add(Dense(neuron1,input_dim = 9,kernel_initializer = init,activation = activation_function))\r\n",
        "    m.add(Dropout(dropout_rate))\r\n",
        "    m.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\r\n",
        "    m.add(Dropout(dropout_rate))\r\n",
        "    m.add(Dense(1,kernel_initializer='normal'))\r\n",
        "    \r\n",
        "    adam = Adam(lr = learning_rate)\r\n",
        "    m.compile(loss = 'mean_squared_error',optimizer = adam)\r\n",
        "    return m\r\n",
        "\r\n",
        "# Create the model\r\n",
        "\r\n",
        "model = KerasRegressor(build_fn = create_model,verbose = 0)\r\n",
        "\r\n",
        "# Define the grid search parameters\r\n",
        "\r\n",
        "batch_size = [10]\r\n",
        "epochs = [100,200,300]\r\n",
        "learning_rate = [0.001,0.01]\r\n",
        "dropout_rate = [0.0,0.1]\r\n",
        "activation_function = ['relu','linear']\r\n",
        "init = ['uniform','normal']\r\n",
        "neuron1 = [8,14]\r\n",
        "neuron2 = [6,9]\r\n",
        "\r\n",
        "# Make a dictionary of the grid search parameters\r\n",
        "\r\n",
        "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\r\n",
        "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\r\n",
        "\r\n",
        "# Build and fit the GridSearchCV\r\n",
        "\r\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\r\n",
        "grid_result = grid.fit(np.array(x_standardized),np.array(y))\r\n",
        "\r\n",
        "print(\"------------------------------- Done -----------------------------\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-155.953, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-97.222, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2108.024, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   16.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-440.998, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   22.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1423.421, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   28.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-152.297, total=   4.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   33.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-100.746, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   39.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2137.244, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   45.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-442.203, total=   5.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   51.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1427.580, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-154.145, total=   4.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-111.363, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2104.571, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-443.406, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1419.426, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-151.147, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-98.925, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2135.079, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-440.696, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1423.955, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-134.040, total=   4.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-101.731, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2277.037, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-439.783, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1440.747, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-156.425, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-104.036, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2295.474, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-447.165, total=   6.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1434.313, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-127.348, total=   4.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-104.062, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2286.700, total=   6.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-445.078, total=   6.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1428.549, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-153.022, total=   4.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-129.399, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2296.934, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-464.490, total=   6.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1439.667, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-148.953, total=   4.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-97.474, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2108.733, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-441.438, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1415.315, total=   6.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-151.494, total=   4.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-100.097, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2128.336, total=   6.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-440.536, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1412.162, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-153.418, total=   4.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-99.527, total=   6.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2133.107, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-445.016, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1426.809, total=   6.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.266, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-109.337, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2139.318, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-449.162, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1432.946, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-156.209, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-123.624, total=   6.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2349.120, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-487.047, total=   6.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1415.510, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-221.932, total=   4.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-129.568, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2339.430, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-461.694, total=   6.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1453.920, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-141.882, total=   5.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-116.557, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2296.178, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-626.721, total=   6.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1429.344, total=   7.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-93.786, total=   4.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-183.472, total=   6.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2384.211, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-725.403, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1441.339, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-157.020, total=   8.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-99.377, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2134.903, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-439.647, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1448.616, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-156.851, total=   8.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-103.147, total=  12.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2164.000, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-441.187, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1453.218, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-154.689, total=   9.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-102.648, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2191.521, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-439.241, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1444.498, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-154.768, total=   9.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-109.557, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2172.763, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-440.972, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1455.698, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-159.078, total=   8.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-450.454, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2306.535, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-465.791, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1432.503, total=  11.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-480.783, total=   8.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-125.871, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2239.697, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-593.883, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1463.558, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-231.501, total=   9.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-189.162, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2379.754, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-636.794, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1454.723, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-234.726, total=   8.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-623.771, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2372.370, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-664.430, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1444.863, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-151.191, total=   8.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-101.397, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2168.368, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-439.962, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1442.963, total=  11.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-149.507, total=   8.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-121.321, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2172.127, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-440.409, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1447.201, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-154.387, total=   9.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-122.627, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2163.491, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-446.973, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1443.753, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-164.202, total=   8.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-114.292, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2162.889, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-446.757, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1456.724, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-172.630, total=   9.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-77.946, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2266.153, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1164.681, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1411.299, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-179.113, total=   8.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-533.754, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2331.169, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1012.613, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1432.478, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-365.511, total=   8.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1150.823, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2341.969, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-843.992, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1438.169, total=  11.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-571.616, total=   9.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-478.600, total=  11.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2463.604, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-869.155, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1651.688, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-151.727, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-101.441, total=  16.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2177.478, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-439.802, total=  17.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1454.338, total=  16.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-143.880, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-103.604, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2159.392, total=  17.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-441.592, total=  17.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1452.491, total=  17.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-169.494, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-117.299, total=  17.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2167.825, total=  16.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-443.157, total=  16.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1456.187, total=  17.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-153.070, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-115.942, total=  16.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2189.542, total=  16.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-449.209, total=  17.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1440.198, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-905.135, total=  13.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-377.368, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2370.610, total=  18.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-562.750, total=  18.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1425.862, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-181.487, total=  13.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-220.515, total=  18.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2310.148, total=  16.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1875.194, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1406.042, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-807.524, total=  13.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-143.755, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2570.370, total=  18.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2698.893, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1542.668, total=  18.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-279.361, total=  13.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-811.542, total=  17.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2574.450, total=  18.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2002.371, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1297.219, total=  18.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-154.465, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-109.488, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2165.971, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-513.099, total=  17.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1455.030, total=  18.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-152.430, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-108.534, total=  16.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2189.962, total=  18.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-439.988, total=  18.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1454.847, total=  18.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-156.543, total=  13.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-111.374, total=  18.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2188.429, total=  18.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-456.475, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1468.958, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-159.196, total=  13.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-111.060, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2195.484, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-472.739, total=  18.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1471.680, total=  18.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-162.664, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-590.953, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2575.532, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1965.637, total=  17.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1408.694, total=  17.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-980.755, total=  13.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1577.935, total=  17.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2576.126, total=  17.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-835.661, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1627.741, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-542.387, total=  13.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1003.667, total=  16.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2451.403, total=  18.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1469.156, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1500.878, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-214.975, total=  12.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1552.555, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-3020.764, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1021.096, total=  16.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1816.446, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-146.089, total=   4.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-92.352, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2115.515, total=   6.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-439.891, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1410.483, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-154.119, total=   4.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-99.546, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2113.510, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-439.221, total=   6.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1393.004, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-148.703, total=   4.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-88.439, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2117.723, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-439.721, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1405.410, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.698, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-86.959, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2129.829, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-442.195, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1417.913, total=   6.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-116.996, total=   5.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-100.729, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2257.852, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-438.927, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1429.541, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-129.369, total=   4.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-91.199, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2255.981, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-448.143, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1419.263, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-128.172, total=   4.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-139.698, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2277.096, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-455.061, total=   6.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1431.305, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-134.885, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-123.489, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2273.095, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-467.917, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1422.498, total=   6.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-131.534, total=   4.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-96.995, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2108.221, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-449.965, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1403.745, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-147.130, total=   4.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-90.073, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2125.143, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-438.108, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1416.930, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-142.843, total=   4.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-100.671, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2121.488, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-441.004, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1408.472, total=   6.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-141.503, total=   4.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-95.134, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2130.972, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-441.598, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1425.101, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-146.564, total=   4.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-100.671, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2197.466, total=   6.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-471.150, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1413.141, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-133.745, total=   4.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-122.133, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2315.202, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-484.434, total=   6.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1459.221, total=   6.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-136.868, total=   4.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-92.642, total=   6.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2294.000, total=   5.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-656.058, total=   6.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1410.778, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-112.300, total=   4.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-109.460, total=   6.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2284.082, total=   5.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-707.561, total=   6.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1442.906, total=   7.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-141.269, total=   8.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-91.666, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2150.560, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-437.963, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1418.427, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-141.842, total=   8.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-96.277, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2157.745, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-437.567, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1439.248, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-142.203, total=   8.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-97.079, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2158.573, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-440.305, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1427.362, total=  12.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-144.065, total=   9.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-92.182, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2164.903, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-441.650, total=  12.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1442.270, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-132.237, total=   9.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-97.798, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2232.875, total=  11.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-900.636, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1396.876, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-130.862, total=   9.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-188.504, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2261.909, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-758.676, total=  11.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1389.487, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-143.749, total=   8.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-283.452, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2417.820, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-595.613, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1454.233, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-196.541, total=   8.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-411.588, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2256.184, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-614.062, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1445.541, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-146.118, total=   8.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-84.716, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2152.056, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-441.045, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1419.640, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-150.052, total=   8.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-95.406, total=  11.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2154.036, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-444.370, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1426.887, total=  11.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-143.631, total=   8.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-96.342, total=  11.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2166.035, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-441.010, total=  12.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1436.844, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-146.451, total=   8.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-98.610, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2172.417, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-439.336, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1430.839, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-123.427, total=   9.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-215.958, total=  11.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2057.993, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-702.943, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1421.901, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-126.918, total=   8.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-143.648, total=  11.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2245.892, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-595.832, total=  11.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1418.193, total=  11.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-170.544, total=   8.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-118.485, total=  11.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2378.794, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-755.846, total=  12.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1428.061, total=  12.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-110.330, total=   9.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-205.642, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2238.023, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-593.465, total=  12.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1347.850, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-137.844, total=  14.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-94.275, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2166.417, total=  17.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-437.029, total=  17.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1436.420, total=  17.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-145.202, total=  13.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-90.723, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2183.912, total=  18.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-440.138, total=  18.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1432.350, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-131.337, total=  13.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-86.882, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2191.320, total=  18.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-439.988, total=  18.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1427.109, total=  17.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-140.576, total=  12.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-100.159, total=  18.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2172.666, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-444.759, total=  19.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1448.211, total=  18.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-109.134, total=  13.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-165.037, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2138.261, total=  18.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-762.072, total=  18.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1402.334, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-128.518, total=  12.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-124.898, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2311.353, total=  18.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-642.930, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1407.666, total=  18.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-232.510, total=  12.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-150.525, total=  19.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2144.043, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-841.007, total=  18.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1369.230, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-156.826, total=  14.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-301.049, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2218.664, total=  17.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-772.910, total=  17.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1327.383, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-130.902, total=  12.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-100.035, total=  17.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2171.065, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-439.620, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1460.464, total=  18.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-146.309, total=  13.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-97.176, total=  17.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2162.732, total=  17.5s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-438.838, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1439.096, total=  17.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-137.771, total=  13.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-99.456, total=  17.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2184.224, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-442.068, total=  17.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1431.743, total=  17.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-143.786, total=  13.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-99.500, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2182.509, total=  18.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-461.950, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1451.359, total=  18.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-144.327, total=  13.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-213.505, total=  19.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2432.460, total=  18.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-535.802, total=  18.3s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1377.975, total=  17.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-121.367, total=  14.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-156.857, total=  18.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2157.074, total=  18.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-675.841, total=  18.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1386.569, total=  17.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-184.292, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-108.383, total=  17.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2228.699, total=  17.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1041.687, total=  17.7s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1628.871, total=  17.6s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-240.525, total=  12.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-281.620, total=  17.1s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2449.498, total=  16.8s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-710.166, total=  17.0s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1425.281, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-143.718, total=   4.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-92.386, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2127.334, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-437.780, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1395.924, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-145.121, total=   4.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-99.707, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2141.697, total=   5.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-438.560, total=   5.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1393.387, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-145.049, total=   4.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-96.854, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2141.107, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-437.944, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1393.147, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-144.917, total=   4.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-100.733, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2149.112, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-437.710, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1397.373, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-150.069, total=   4.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-87.998, total=   5.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2139.218, total=   5.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-437.774, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1371.357, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-139.853, total=   4.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-83.590, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2150.536, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-438.379, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1377.775, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-171.050, total=   4.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-99.683, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2148.442, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-436.022, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1390.170, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-146.342, total=   5.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-86.931, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2146.748, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-435.345, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1374.864, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-144.061, total=   4.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-93.161, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2145.007, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.331, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1383.715, total=   6.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-145.615, total=   5.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-93.974, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2145.208, total=   6.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-438.028, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1400.977, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-144.026, total=   4.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-97.420, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2145.486, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-438.211, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1396.674, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-142.568, total=   4.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-96.644, total=   5.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2145.110, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-436.778, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1392.250, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-151.059, total=   4.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-76.507, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2150.796, total=   5.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-437.719, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1390.648, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-146.697, total=   4.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-124.083, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2154.212, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-440.179, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1393.285, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-137.710, total=   4.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-107.713, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2135.609, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-436.678, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1383.125, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-196.763, total=   4.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-87.888, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2146.457, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-439.239, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1392.389, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-145.631, total=   9.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-96.441, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2148.585, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.129, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1413.122, total=  12.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-145.211, total=   9.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-99.276, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2144.301, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-436.481, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1393.658, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-147.419, total=   8.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-98.531, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2152.202, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-436.222, total=  11.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1406.267, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-145.437, total=   8.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-106.629, total=  11.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2149.647, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-435.521, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1392.837, total=  12.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-131.932, total=   8.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-98.926, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2142.236, total=  12.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-446.858, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1389.609, total=  12.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-133.741, total=   9.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-90.100, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2146.048, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-435.457, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1401.109, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-135.541, total=   8.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-98.143, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2146.965, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-436.885, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1400.218, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-140.332, total=   8.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-94.536, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2147.915, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-434.563, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1393.592, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-143.552, total=   8.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-95.408, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2149.042, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.953, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1391.392, total=  11.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-149.226, total=   8.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-93.764, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2143.092, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-437.423, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1400.596, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-140.971, total=   8.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-103.146, total=  11.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2150.684, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-438.292, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1401.773, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-143.302, total=   7.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-92.807, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2152.959, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-437.469, total=  10.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1396.335, total=  10.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-153.031, total=   8.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-106.471, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2153.670, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-436.769, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1370.337, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-151.212, total=   8.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-95.943, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2141.612, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-437.392, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1402.775, total=  11.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-164.829, total=   8.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-90.813, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2152.157, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-436.474, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1381.765, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-133.139, total=   8.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-84.443, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2149.869, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-436.233, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1383.707, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-145.866, total=  12.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-100.226, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2148.936, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.696, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1402.648, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-145.367, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-97.092, total=  17.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2150.164, total=  16.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-437.660, total=  16.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1412.157, total=  17.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-144.265, total=  12.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-96.148, total=  16.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2150.770, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-439.370, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1397.466, total=  16.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-150.106, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-98.393, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2149.136, total=  16.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-437.207, total=  16.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1405.011, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-144.053, total=  13.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-102.782, total=  16.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2145.793, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-436.393, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1393.986, total=  18.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-136.525, total=  13.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-88.178, total=  17.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2145.761, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-436.267, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1384.643, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-139.648, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-99.629, total=  16.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2152.859, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-436.870, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1386.119, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-136.560, total=  13.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-86.093, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2143.259, total=  16.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-436.176, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1404.948, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-145.050, total=  12.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-96.223, total=  16.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2149.424, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-437.103, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1403.031, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-143.113, total=  12.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-99.801, total=  17.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2147.161, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-436.137, total=  18.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1399.147, total=  16.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-145.915, total=  12.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-93.703, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2152.085, total=  16.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-438.879, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1411.104, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-148.884, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-93.273, total=  17.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2157.020, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-436.753, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1397.847, total=  16.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-136.389, total=  12.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-84.363, total=  17.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2145.104, total=  16.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-436.201, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1391.174, total=  16.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-140.395, total=  12.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-101.309, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2147.612, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-437.380, total=  16.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1404.199, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-134.577, total=  12.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-88.492, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2145.687, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-437.978, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1384.193, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-136.783, total=  12.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-88.321, total=  16.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2147.985, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-436.595, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.0, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1401.402, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-134.875, total=   5.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-84.511, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2143.109, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.730, total=   6.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1387.532, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-140.616, total=   4.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-90.648, total=   7.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2131.973, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-435.590, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1386.109, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-141.505, total=   4.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-93.233, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2140.736, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-436.355, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1393.347, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-142.669, total=   4.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-89.859, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2147.184, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-434.951, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1388.209, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-112.163, total=   4.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-71.521, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2148.127, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-434.577, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1409.550, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-147.303, total=   4.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-84.376, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2143.167, total=   6.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-434.443, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1388.184, total=   6.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-150.996, total=   4.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-84.358, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2147.335, total=   6.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-438.760, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1385.113, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-147.643, total=   4.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-83.725, total=   6.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2146.375, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-435.396, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1385.823, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-133.991, total=   4.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-91.450, total=   6.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2140.375, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-435.754, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1380.306, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-135.807, total=   4.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-95.346, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2138.749, total=   6.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-436.938, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1382.534, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-137.989, total=   4.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-92.500, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2146.009, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-437.470, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1384.354, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-139.207, total=   4.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-88.782, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2142.314, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-437.365, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1396.706, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-140.004, total=   4.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-76.290, total=   6.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2140.303, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-436.592, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1390.418, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-157.252, total=   4.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-79.778, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2150.823, total=   5.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-433.402, total=   6.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1377.031, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-129.104, total=   4.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-103.263, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2150.273, total=   6.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-436.480, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1388.802, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-160.383, total=   4.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-80.212, total=   6.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2145.153, total=   5.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-437.367, total=   5.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1400.791, total=   6.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-141.635, total=   8.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-91.189, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2147.277, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-435.585, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1394.940, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-142.812, total=   8.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-95.021, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2147.090, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-436.845, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1394.780, total=  11.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-138.490, total=   8.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-102.919, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2152.948, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-435.249, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1386.411, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-143.430, total=   8.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-91.829, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2143.742, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-436.230, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1389.112, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-134.434, total=   9.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-81.774, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2142.481, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-435.314, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1397.407, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-133.118, total=   8.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-98.557, total=  11.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2151.090, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-438.409, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1372.276, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-150.128, total=   8.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-81.956, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2126.751, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-434.651, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1370.435, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-139.939, total=   8.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-85.276, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2132.108, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-435.721, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1367.306, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-140.599, total=   8.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-105.683, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2147.608, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.731, total=  12.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1391.648, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-139.927, total=   8.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-90.869, total=  12.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2144.199, total=  12.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-435.845, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1399.588, total=  11.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-141.886, total=   8.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-89.051, total=  11.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2149.636, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-435.761, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1392.276, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-139.016, total=   8.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-89.802, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2153.348, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-436.892, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1397.355, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-131.995, total=   8.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-86.450, total=  11.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2134.712, total=  11.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-436.015, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1398.700, total=  11.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-137.731, total=   9.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-79.999, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2146.752, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-435.279, total=  12.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1365.300, total=  12.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-135.101, total=   9.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-89.114, total=  11.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2135.892, total=  11.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-435.762, total=  12.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1369.113, total=  11.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-145.619, total=   8.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-94.412, total=  11.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2147.094, total=  10.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-440.128, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=200, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1393.836, total=  12.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-138.438, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-91.118, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-2148.023, total=  17.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-436.479, total=  17.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=6, score=-1386.940, total=  18.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-144.505, total=  12.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-90.621, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-2142.156, total=  18.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-436.612, total=  17.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=8, neuron2=9, score=-1393.352, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-139.976, total=  12.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-89.859, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-2148.366, total=  16.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-436.117, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=6, score=-1390.880, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-134.218, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-98.476, total=  16.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-2153.566, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-436.942, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.001, neuron1=14, neuron2=9, score=-1389.089, total=  17.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-135.199, total=  12.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-89.803, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-2134.948, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-435.726, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=6, score=-1396.751, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-135.600, total=  12.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-89.318, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-2149.435, total=  16.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-436.257, total=  16.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=8, neuron2=9, score=-1376.065, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-136.584, total=  13.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-86.082, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-2144.163, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-438.364, total=  18.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=6, score=-1371.533, total=  18.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-136.942, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-100.878, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-2144.591, total=  17.9s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-435.730, total=  17.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=uniform, learning_rate=0.01, neuron1=14, neuron2=9, score=-1391.842, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-139.099, total=  13.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-99.668, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-2141.669, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-437.196, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=6, score=-1403.375, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-136.906, total=  12.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-92.192, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-2146.613, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-439.043, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=8, neuron2=9, score=-1392.568, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-139.689, total=  13.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-86.674, total=  18.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-2148.628, total=  18.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-436.394, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=6, score=-1391.931, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-144.270, total=  13.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-91.191, total=  18.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-2128.751, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-437.423, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.001, neuron1=14, neuron2=9, score=-1387.525, total=  18.0s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-136.093, total=  13.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-82.370, total=  17.8s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-2144.234, total=  18.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-436.857, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=6, score=-1373.022, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-133.380, total=  13.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-90.960, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-2139.857, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-437.263, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=8, neuron2=9, score=-1357.135, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-131.093, total=  13.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-85.441, total=  17.6s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-2124.776, total=  17.7s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-437.039, total=  17.5s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=6, score=-1388.008, total=  17.3s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-133.778, total=  12.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-74.717, total=  17.2s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-2129.222, total=  17.4s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-437.048, total=  17.1s\n",
            "[CV] activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9 \n",
            "[CV]  activation_function=linear, batch_size=10, dropout_rate=0.1, epochs=300, init=normal, learning_rate=0.01, neuron1=14, neuron2=9, score=-1381.087, total=  16.8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 960 out of 960 | elapsed: 179.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------- Done -----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIBES8kVNwIM",
        "outputId": "16671b72-ec2c-4fc1-c0fc-4aab73733a20"
      },
      "source": [
        "# Summarize the results\r\n",
        "print(\"------------------ Results-----------------------------------------------\")\r\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))\r\n",
        "print(\"********************* Done ************************\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------ Results-----------------------------------------------\n",
            "Best : -831.1702133178711, using {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-845.1234680175781,790.8191597993882 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-852.0140045166015,800.6304328790077 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-846.5821823120117,786.5435938823923 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-849.9603485107422,800.1114874129471 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-878.6674591064453,851.127682205604 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-887.4826110839844,851.3020794790791 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-878.3472030639648,852.9266806170895 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-896.7021697998047,846.6500767991952 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-842.3826843261719,790.9973129645025 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-846.5249298095703,795.9945742695071 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-851.5755798339844,798.9378342808432 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-856.2056640625,800.1070005542225 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-906.3019805908203,859.3038644445064 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-921.3088897705078,851.1134948868954 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-922.1363708496094,835.4969387884814 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-965.6422714233398,856.5352868264067 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-855.912631225586,802.6440371337987 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-863.6806579589844,811.7766458563651 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-866.5193023681641,820.0558632741563 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-866.7517105102539,814.1346680997425 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-962.8720764160156,797.7128641953664 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-980.7582580566407,767.919373013885 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-978.386865234375,835.2396116862035 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-1068.0318267822265,761.3094649330985 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-860.7760772705078,813.1408120462596 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-866.1127838134765,811.5170299425629 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-866.2463272094726,806.4564920720629 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-868.9726440429688,807.9828199107941 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-1018.5417449951171,816.3866282241709 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-1097.8253326416016,748.678631920745 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-1228.0926208496094,660.6667704054832 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-1206.9327209472656,751.6940972029762 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-864.9573257446289,817.6175133708741 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-860.1917861938476,812.3415143067012 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-870.7925003051757,808.384106582119 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-869.5919967651367,815.5945283432513 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-1128.3449401855469,716.299403718438 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-1198.6772521972657,863.4258138080323 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-1552.6419006347655,988.9311014475563 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-1392.9884094238282,819.0991050355502 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-879.610595703125,804.8710158213349 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-869.1523056030273,820.2427999397427 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-876.3557189941406,818.8215589648524 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-882.0317184448243,819.4206683367589 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-1340.696078491211,879.7580615187666 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-1519.643798828125,614.7312144794465 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-1393.4984008789063,634.4721949244091 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-1525.167300415039,926.617049739131 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-840.8659729003906,794.0984458336249 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-839.8800735473633,788.285516474265 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-839.9992416381835,794.3833650438528 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-845.5189514160156,799.7432674230917 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-868.8090606689453,846.6202675999435 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-868.7911499023437,843.2858092846684 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-886.2664947509766,842.553757521505 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-884.3768844604492,840.5046189065253 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-838.0916931152344,791.4900086543533 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-843.4764953613281,798.543160698594 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-842.8954086303711,794.6274817080863 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-846.8613327026367,801.2694146814059 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-865.7984237670898,816.2580191002564 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-902.9471878051758,857.9512801792387 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-918.0694244384765,836.2062600059713 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-931.2615585327148,835.2245027542493 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-847.977018737793,807.6743169938848 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-854.535920715332,812.033952804497 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-853.1044616699219,810.1085216084994 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-857.0138793945313,814.7258074003348 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-952.0844924926757,805.340622099467 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-945.8877105712891,800.2045589426654 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-978.9736358642579,851.4064649506078 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-984.7830383300782,763.6846100232226 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-848.7151275634766,808.4783734249687 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-854.1502014160156,807.1055878038594 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-856.7725784301758,813.6751593361278 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-857.5307205200195,814.1364163881808 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-904.4444381713868,737.9755694104016 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-906.0967041015625,817.5582250285371 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-970.346061706543,849.0686886460884 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-899.0620941162109,798.81738204618 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-854.3969329833984,815.5458033306703 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-858.4651718139648,819.6734494454599 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-855.3272888183594,824.498228301804 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-861.2741165161133,816.8757176988948 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-915.3677139282227,770.5988559131416 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-923.0729995727539,837.7387081612712 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-947.46298828125,743.9481595384198 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-955.3666961669921,752.7821599873448 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-860.417025756836,820.4021573375991 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-856.830241394043,812.5326423080813 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-859.0523574829101,819.1657156452771 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-867.820637512207,818.31479478213 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-940.8140014648437,865.277108260836 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-899.541520690918,777.9154319336752 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-1038.3863204956056,819.7452843176881 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-1021.4178955078125,831.4431965293942 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-839.4283950805664,796.466567220541 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-843.6943115234375,799.0779217558648 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-842.8204071044922,799.4603427087117 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-845.96904296875,801.9670514718867 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-837.2831741333008,796.6891508560989 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-838.0263595581055,803.7846550112449 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-849.0733169555664,796.6248282180169 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-838.0460006713868,800.7087283823807 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-840.4550415039063,800.4645234954588 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-844.7604904174805,802.3036196907356 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-844.3632232666016,801.4141319745914 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-842.6698547363281,801.2283052571612 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-841.3457656860352,805.0815074127936 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-851.6910980224609,798.2052563468142 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-840.1667999267578,795.7023568882613 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-852.5470794677734,793.8781992387976 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-847.9815246582032,804.8210194954195 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-843.7854476928711,800.2372327260463 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-848.1283523559571,804.3239501554989 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-846.0144271850586,800.5595490787441 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-841.9123260498047,800.3727166109003 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-841.2910003662109,805.6553342809666 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-843.5502426147461,803.8725616845212 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-842.187776184082,803.3320833760531 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-843.2695220947265,802.4306295264722 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-844.8201522827148,801.0375961227444 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-846.9733825683594,803.2688150467318 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-844.5745025634766,804.8580559732163 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-844.0556335449219,797.4322196266571 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-845.7867477416992,800.1105638476922 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-845.2075546264648,799.3872157035973 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-837.4782653808594,805.591695792059 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-846.8744857788085,802.669473300042 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-848.4879364013672,804.9644856104587 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-845.6040161132812,803.317684037966 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-847.9705871582031,802.6123815524131 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-844.6014373779296,800.3272999427871 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-838.2748565673828,803.0871310634209 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-843.0250381469726,802.8639879108157 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-841.4070327758789,805.471157083888 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-846.1663330078125,803.7277687448645 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-845.0719390869141,802.2264798111443 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-848.3370239257813,805.852308464381 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-846.7553573608399,805.4014435851188 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-838.6460418701172,804.5110727093324 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-846.1790802001954,803.1431086342079 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-838.1854721069336,803.1134824523189 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-842.2175384521485,806.0078892956515 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-837.3515274047852,803.5472155125975 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-836.9873672485352,797.696413781451 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-841.0353088378906,800.8230687492805 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-840.5744369506835,802.7837438631758 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-835.187777709961,814.8793514948893 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-839.4944885253906,801.7509067373837 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-841.3124053955078,801.6208934374936 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-839.7923782348632,802.4403048440113 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-836.3752685546875,800.628613919195 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-837.8744369506836,799.2403040878955 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-839.66435546875,801.945737047572 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-840.8746932983398,802.9316603156731 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-836.7215179443359,803.7012874987056 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-839.6572540283203,802.0054225060819 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-841.5844741821289,803.6131256311912 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-844.7810119628906,802.379779547635 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 100, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-842.1252044677734,803.6033290866785 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-843.3095336914063,802.4722440723435 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-843.2032699584961,802.6921769834688 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-840.8688522338867,801.1570359501388 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-838.2820343017578,805.437126830955 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-838.6899505615235,801.6185305020141 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-832.7844543457031,793.9384789313099 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-832.0697540283203,796.29339349362 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-844.4538284301758,800.6328226001453 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-842.0858215332031,803.5785564426179 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-841.7220809936523,804.3428933765584 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-843.2826950073243,806.4920381011286 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-837.5742828369141,802.584517155945 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-833.0120742797851,802.2316138616228 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-832.9964614868164,797.893816361195 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-844.2178924560546,801.6361288107798 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 200, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-840.1996231079102,803.2322981155008 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-841.4494323730469,801.2244517853011 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-841.0394012451172,803.8846432083099 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-842.4582000732422,804.6570611059258 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-838.4856018066406,801.2275366356813 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-837.3347885131836,803.0765827470308 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-835.3452713012696,800.9690008518152 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-841.9964065551758,801.3104434744843 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "-844.2013336181641,801.6543736757396 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 6}\n",
            "-841.4643798828125,803.3534025269132 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 9}\n",
            "-840.6631408691406,804.7319569351944 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 6}\n",
            "-837.8317810058594,795.9226959305365 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 14, 'neuron2': 9}\n",
            "-834.5149230957031,802.1222558045171 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 6}\n",
            "-831.7189819335938,797.4064650006061 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 9}\n",
            "-833.2712173461914,798.125514309095 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 6}\n",
            "-831.1702133178711,800.157147741031 with: {'activation_function': 'linear', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 300, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 14, 'neuron2': 9}\n",
            "********************* Done ************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdwL_-eYON5M",
        "outputId": "b5130c39-3ea7-4d4a-f905-c553e2ea9a58"
      },
      "source": [
        "# after applying general model get the best hyperparameters and make another model model_1 :\r\n",
        "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\r\n",
        "    m = Sequential()\r\n",
        "    m.add(Dense(neuron1,input_dim = 9,kernel_initializer = init,activation = activation_function))\r\n",
        "    m.add(Dropout(dropout_rate))\r\n",
        "    m.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\r\n",
        "    m.add(Dropout(dropout_rate))\r\n",
        "    m.add(Dense(1,kernel_initializer='normal'))\r\n",
        "    \r\n",
        "    adam = Adam(lr = learning_rate)\r\n",
        "    m.compile(loss = 'mean_squared_error',optimizer = adam)\r\n",
        "    return m\r\n",
        "\r\n",
        "# Create the model\r\n",
        "\r\n",
        "model_1 = KerasRegressor(build_fn = create_model,verbose = 0)\r\n",
        "\r\n",
        "# Define the grid search parameters\r\n",
        "\r\n",
        "batch_size = [10]\r\n",
        "epochs = [500]\r\n",
        "learning_rate = [0.01]\r\n",
        "dropout_rate = [0.0]\r\n",
        "activation_function = ['relu']\r\n",
        "init = ['uniform']\r\n",
        "neuron1 = [8]\r\n",
        "neuron2 = [8]\r\n",
        "\r\n",
        "# Make a dictionary of the grid search parameters\r\n",
        "\r\n",
        "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\r\n",
        "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\r\n",
        "\r\n",
        "# Build and fit the GridSearchCV\r\n",
        "\r\n",
        "grid = GridSearchCV(estimator = model_1,param_grid = param_grids,cv = KFold(),verbose = 10)\r\n",
        "grid_result = grid.fit(np.array(x_standardized),np.array(y))\r\n",
        "\r\n",
        "print(\"------------------------------- Done -----------------------------\")\r\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-145.258, total=  21.4s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-475.141, total=  28.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   50.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-2393.952, total=  29.9s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.3min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-1680.155, total=  28.2s\n",
            "[CV] activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=500, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8, score=-1408.607, total=  28.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------------------- Done -----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Ritu-dPbZv",
        "outputId": "8fd54af2-36e6-48b4-ff35-52a86415d5c8"
      },
      "source": [
        "# Summarize the results for new model :\r\n",
        "print(\"------------------ Results-----------------------------------------------\")\r\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))\r\n",
        "print(\"********************* Done ************************\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------ Results-----------------------------------------------\n",
            "Best : -1220.622366333008, using {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 500, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 8}\n",
            "-1220.622366333008,816.7449226363104 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 500, 'init': 'uniform', 'learning_rate': 0.01, 'neuron1': 8, 'neuron2': 8}\n",
            "********************* Done ************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA5jMquDP6rk",
        "outputId": "b7261df0-3c3b-45de-d6a5-131dd9d26ae6"
      },
      "source": [
        "# apply hyperparameters to get better model :\r\n",
        "import numpy as np\r\n",
        "# Create the model :\r\n",
        "kfold = KFold(n_splits=10)\r\n",
        "def create_model():\r\n",
        "    m = Sequential()\r\n",
        "    m.add(Dense(8, input_dim=9, kernel_initializer = 'normal', activation='relu'))\r\n",
        "    m.add(Dense(6, kernel_initializer='normal', activation='relu'))\r\n",
        "    # m.add(Dense(3, kernel_initializer='normal', activation='linear'))\r\n",
        "    m.add(Dense(1, kernel_initializer='normal'))\r\n",
        "    \r\n",
        "    adam=Adam(lr=0.01)\r\n",
        "#     optimizer = Adadelta()\r\n",
        "# compile model :\r\n",
        "    m.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse'])\r\n",
        "    return m\r\n",
        "\r\n",
        "final_model = create_model()\r\n",
        "history = final_model.fit(np.array(x_standardized), np.array(y), epochs=500, batch_size=10, verbose=0)\r\n",
        "print(history)\r\n",
        "print(\"********************************done***********************************\")"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.callbacks.History object at 0x7ff426f237b8>\n",
            "********************************done***********************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XM1wKkAQpA1",
        "outputId": "16d7f315-2e07-4bea-e9a3-152616b2e76e"
      },
      "source": [
        "# now apply final model on testing and training data :\r\n",
        "mse_value, mae_value = final_model.evaluate(x_test, y_test, verbose=0)\r\n",
        "\r\n",
        "print(mse_value)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "148.7102508544922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb1gTBJGR4Z1"
      },
      "source": [
        "# predict test data :\r\n",
        "final_y_test_pred = final_model.predict(x_test)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "a07aMTWfSRIG",
        "outputId": "55e7620b-afe4-4b41-888d-6d8aca7cb99c"
      },
      "source": [
        "# testing score :\r\n",
        "print(r2_score(final_y_test_pred, y_test))    \r\n",
        "plt.scatter(final_y_test_pred, y_test)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02420879975232504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7ff425cce390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2HZHr_iSgjE"
      },
      "source": [
        "# training data prediction :\r\n",
        "final_y_train_pred = final_model.predict(x_train)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSCq_iLsSo4b",
        "outputId": "75e47202-55e6-4fd0-af56-7738be5ad683"
      },
      "source": [
        "# accuracy score for training data using final_model :\r\n",
        "print(r2_score(final_y_train_pred, y_train))    # 67.64 % training accuracy "
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6764932789427471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "SLmZqr1rS2zh",
        "outputId": "40f0ec5f-7412-4117-91ff-462232f6fc95"
      },
      "source": [
        "# visulize loss w.r.t epochs :\r\n",
        "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,6))\r\n",
        "ax2.plot(history.history['mse'], color='orange')\r\n",
        "ax2.legend(loc='upper right')\r\n",
        "ax1.plot(history.history['loss'], label='Loss')\r\n",
        "ax1.legend(loc=\"upper right\")\r\n",
        "ax1.set_title(\"Model-Accuracy w.r.t Epochs\", loc='center')\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"mean-squared-error\")\r\n",
        "ax1.set_xlabel(\"Epoch\")\r\n",
        "ax1.set_ylabel(\"Loss\")\r\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL7Y-BPubxHa"
      },
      "source": [
        "Therefor, we can conclude that model made of extracted feature doesn't give good prediction , Thats why model made of using whole features is good model."
      ]
    }
  ]
}